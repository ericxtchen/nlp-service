version: "3.9"
services:
  nlp-service:
    build: .
    container_name: nlp-service
    # Use GPU
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Live-mount source code for fast dev iteration
    volumes:
      - .:/app
    # Override command so container restarts on code change (dev)
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    environment:
      - TRANSFORMERS_CACHE=/app/.cache
      - CUDA_VISIBLE_DEVICES=0
